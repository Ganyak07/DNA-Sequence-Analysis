{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "How many alignments does the naive exact matching algorithm try when matching the string\n",
        "GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG\n",
        "GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG (derived from human Alu sequences) to the excerpt of human chromosome 1?  (Don't consider reverse complements.)"
      ],
      "metadata": {
        "id": "MG4TEbIMTj7f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVt6e1tUScn6",
        "outputId": "18c9b8ec-6da9-4a2c-9e36-fb369a64f0bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alignment found at index: 56922\n",
            "Total alignments tried: 799954\n"
          ]
        }
      ],
      "source": [
        "def naive_exact_match(pattern, text):\n",
        "    alignments = 0\n",
        "    pattern_length = len(pattern)\n",
        "    text_length = len(text)\n",
        "\n",
        "    for i in range(text_length - pattern_length + 1):\n",
        "        alignments += 1\n",
        "        if text[i:i+pattern_length] == pattern:\n",
        "            print(\"Alignment found at index:\", i)\n",
        "\n",
        "    return alignments\n",
        "\n",
        "# Define the pattern and text\n",
        "pattern = \"GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG\"\n",
        "with open(\"chr1.GRCh38.excerpt.fasta\") as f:\n",
        "    lines = f.readlines()[1:]\n",
        "    text = ''.join(line.strip() for line in lines)\n",
        "\n",
        "# Count alignments\n",
        "alignments = naive_exact_match(pattern, text)\n",
        "print(\"Total alignments tried:\", alignments)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. How many character comparisons does the naive exact matching algorithm try when matching the string\n",
        "GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG\n",
        "GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG (derived from human Alu sequences) to the excerpt of human chromosome 1?  (Don't consider reverse complements."
      ],
      "metadata": {
        "id": "ITR3NqptUGmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_exact_match(pattern, text):\n",
        "    comparisons = 0\n",
        "    alignments = 0\n",
        "    pattern_length = len(pattern)\n",
        "    text_length = len(text)\n",
        "\n",
        "    for i in range(text_length - pattern_length + 1):\n",
        "        alignments += 1\n",
        "        for j in range(pattern_length):\n",
        "            comparisons += 1\n",
        "            if text[i+j] != pattern[j]:\n",
        "                break\n",
        "\n",
        "    return comparisons\n",
        "\n",
        "# Define the pattern and text\n",
        "pattern = \"GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG\"\n",
        "with open(\"chr1.GRCh38.excerpt.fasta\") as f:\n",
        "    lines = f.readlines()[1:]\n",
        "    text = ''.join(line.strip() for line in lines)\n",
        "\n",
        "# Count character comparisons\n",
        "comparisons = naive_exact_match(pattern, text)\n",
        "print(\"Total character comparisons tried:\", comparisons)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vldXQZv_UFW7",
        "outputId": "cce902fc-143a-4023-f19b-44b444b81b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total character comparisons tried: 984143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.How many alignments does Boyer-Moore try when matching the string\n",
        "GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG\n",
        "GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG (derived from human Alu sequences) to the excerpt of human chromosome 1?  (Don't consider reverse complements.)"
      ],
      "metadata": {
        "id": "CaivcUSXUu7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def boyer_moore_with_count(p, p_bm, t):\n",
        "    \"\"\" Do Boyer-Moore matching \"\"\"\n",
        "    occurrences = []\n",
        "    alignments_tried = 0\n",
        "    i = 0\n",
        "    while i < len(t) - len(p) + 1:\n",
        "        shift = 1\n",
        "        mismatched = False\n",
        "        alignments_tried += 1\n",
        "        for j in range(len(p) - 1, -1, -1):\n",
        "            if p[j] != t[i+j]:\n",
        "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
        "                skip_gs = p_bm.good_suffix_rule(j)\n",
        "                shift = max(shift, skip_bc, skip_gs)\n",
        "                mismatched = True\n",
        "                break\n",
        "        if not mismatched:\n",
        "            occurrences.append(i)\n",
        "            skip_gs = p_bm.match_skip()\n",
        "            shift = max(shift, skip_gs)\n",
        "        i += shift\n",
        "    return occurrences, alignments_tried\n",
        "\n",
        "from bm_preproc import BoyerMoore\n",
        "\n",
        "# Load the excerpt of human chromosome 1\n",
        "with open(\"chr1.GRCh38.excerpt.fasta\") as f:\n",
        "    lines = f.readlines()[1:]\n",
        "    t = ''.join(line.strip() for line in lines)\n",
        "\n",
        "# Define the pattern\n",
        "p = \"GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG\"\n",
        "\n",
        "# Preprocess the pattern for Boyer-Moore\n",
        "p_bm = BoyerMoore(p)\n",
        "\n",
        "# Perform Boyer-Moore matching with count\n",
        "occurrences, alignments_tried = boyer_moore_with_count(p, p_bm, t)\n",
        "\n",
        "print(\"Total alignments tried by Boyer-Moore:\", alignments_tried)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIv7eMvBZHip",
        "outputId": "d8e0b8d1-9a26-40f7-d701-b46cbd8239cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total alignments tried by Boyer-Moore: 127974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bisect\n",
        "\n",
        "class Index(object):\n",
        "    def __init__(self, t, k):\n",
        "        ''' Create index from all substrings of size 'length' '''\n",
        "        self.k = k  # k-mer length (k)\n",
        "        self.index = []\n",
        "        for i in range(len(t) - k + 1):  # for each k-mer\n",
        "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
        "        self.index.sort()  # alphabetize by k-mer\n",
        "\n",
        "    def query(self, p):\n",
        "        ''' Return index hits for first k-mer of P '''\n",
        "        kmer = p[:self.k]  # query with first k-mer\n",
        "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search\n",
        "        hits = []\n",
        "        while i < len(self.index):  # collect matching index entries\n",
        "            if self.index[i][0] != kmer:\n",
        "                break\n",
        "            hits.append(self.index[i][1])\n",
        "            i += 1\n",
        "        return hits\n",
        "\n",
        "def approximate_match_index(p, t, index, k):\n",
        "    segment_length = len(p) // 3\n",
        "    all_matches = set()\n",
        "    hits = 0\n",
        "    for i in range(3):\n",
        "        start = i * segment_length\n",
        "        end = (i + 1) * segment_length\n",
        "        matches = index.query(p[start:end])\n",
        "        hits += len(matches)\n",
        "        for match in matches:\n",
        "            if match < start or match - start + len(p) > len(t):\n",
        "                continue\n",
        "            mismatches = 0\n",
        "            for j in range(start):\n",
        "                if p[j] != t[match - start + j]:\n",
        "                    mismatches += 1\n",
        "                    if mismatches > 2:\n",
        "                        break\n",
        "            for j in range(end, len(p)):\n",
        "                if p[j] != t[match - start + j]:\n",
        "                    mismatches += 1\n",
        "                    if mismatches > 2:\n",
        "                        break\n",
        "            if mismatches <= 2:\n",
        "                all_matches.add(match - start)\n",
        "    return list(all_matches), hits\n",
        "\n",
        "# Load the excerpt of human chromosome 1\n",
        "with open(\"chr1.GRCh38.excerpt.fasta\") as f:\n",
        "    lines = f.readlines()[1:]\n",
        "    text = ''.join(line.strip() for line in lines)\n",
        "\n",
        "# Create the index\n",
        "from kmer_index import Index\n",
        "index = Index(text, 8)\n",
        "\n",
        "# Define the pattern\n",
        "pattern = \"GGCGCGGTGGCTCACGCCTGTAAT\"\n",
        "\n",
        "# Find approximate matches using the index\n",
        "matches, hits = approximate_match_index(pattern, text, index, 8)\n",
        "print(\"Total approximate matches found:\", len(matches))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnCO43eIUx69",
        "outputId": "548327d5-ef53-45ec-aa94-205e05b88bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total approximate matches found: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the excerpt of human chromosome 1\n",
        "with open(\"chr1.GRCh38.excerpt.fasta\") as f:\n",
        "    lines = f.readlines()[1:]\n",
        "    text = ''.join(line.strip() for line in lines)\n",
        "\n",
        "# Create the index\n",
        "from kmer_index import Index\n",
        "index = Index(text, 8)\n",
        "\n",
        "# Define the pattern\n",
        "pattern = \"GGCGCGGTGGCTCACGCCTGTAAT\"\n",
        "\n",
        "# Find approximate matches using the index\n",
        "matches, hits = approximate_match_index(pattern, text, index, 8)\n",
        "print(\"Total index hits:\", hits)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYfYAa8oVrOp",
        "outputId": "8c5e4e93-9835-47fd-c2eb-a062686b38ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total index hits: 90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bisect\n",
        "\n",
        "class SubseqIndex(object):\n",
        "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
        "\n",
        "    def __init__(self, t, k, ival):\n",
        "        \"\"\" Create index from all subsequences consisting of k characters\n",
        "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
        "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
        "        self.k = k  # num characters per subsequence extracted\n",
        "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
        "        self.index = []\n",
        "        self.span = 1 + ival * (k - 1)\n",
        "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
        "            self.index.append((t[i:i+self.span:ival], i))  # add (subseq, offset)\n",
        "        self.index.sort()  # alphabetize by subseq\n",
        "\n",
        "    def query(self, p):\n",
        "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
        "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
        "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
        "        hits = []\n",
        "        while i < len(self.index):  # collect matching index entries\n",
        "            if self.index[i][0] != subseq:\n",
        "                break\n",
        "            hits.append(self.index[i][1])\n",
        "            i += 1\n",
        "        return hits\n",
        "\n",
        "def count_mismatches(seq1, seq2):\n",
        "    \"\"\" Count the number of mismatches between two sequences \"\"\"\n",
        "    return sum(1 for base1, base2 in zip(seq1, seq2) if base1 != base2)\n",
        "\n",
        "def approximate_match_subseq_index(pattern, text, index):\n",
        "    \"\"\" Find all approximate occurrences of pattern in text using SubseqIndex \"\"\"\n",
        "    k = index.k\n",
        "    ival = index.ival\n",
        "    hits = set()\n",
        "\n",
        "    # Find hits for first subsequence of pattern\n",
        "    subseq_hits = index.query(pattern)\n",
        "    for hit in subseq_hits:\n",
        "        if hit not in hits:\n",
        "            hits.add(hit)\n",
        "\n",
        "    # Check remaining subsequences of pattern\n",
        "    for i in range(1, (len(pattern) - k) // ival + 1):\n",
        "        subseq = pattern[i * ival:i * ival + k]\n",
        "        subseq_hits = index.query(subseq)\n",
        "        for hit in subseq_hits:\n",
        "            if hit - i * ival not in hits:\n",
        "                hits.add(hit - i * ival)\n",
        "\n",
        "    # Check for mismatches\n",
        "    matches = []\n",
        "    for hit in hits:\n",
        "        if count_mismatches(text[hit:hit+len(pattern)], pattern) <= 2:\n",
        "            matches.append(hit)\n",
        "\n",
        "    return matches\n",
        "\n",
        "# Load the excerpt of human chromosome 1\n",
        "with open(\"chr1.GRCh38.excerpt.fasta\") as f:\n",
        "    lines = f.readlines()[1:]\n",
        "    text = ''.join(line.strip() for line in lines)\n",
        "\n",
        "# Define the pattern\n",
        "pattern = \"GGCGCGGTGGCTCACGCCTGTAAT\"\n",
        "\n",
        "# Create SubseqIndex\n",
        "subseq_index = SubseqIndex(text, 8, 3)\n",
        "\n",
        "# Find approximate matches using SubseqIndex\n",
        "matches = approximate_match_subseq_index(pattern, text, subseq_index)\n",
        "print(\"Total index hits for approximate matches:\", len(matches))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ejXtq01W7Dj",
        "outputId": "abc25514-ef03-46da-f9b7-b51c6e4daa17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total index hits for approximate matches: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the edit distance of the best match between pattern\n",
        "GCTGATCGATCGTACG\n",
        "GCTGATCGATCGTACG and the excerpt of human chromosome 1?  (Don't consider reverse complements.)"
      ],
      "metadata": {
        "id": "CyGcGN2Za0MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_distance(str1, str2):\n",
        "    m, n = len(str1), len(str2)\n",
        "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if str1[i - 1] == str2[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "            else:\n",
        "                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n",
        "\n",
        "    return dp[m][n]\n",
        "\n",
        "# Load the excerpt of human chromosome 1\n",
        "with open(\"chr1.GRCh38.excerpt.fasta\") as f:\n",
        "    lines = f.readlines()[1:]\n",
        "    t = ''.join(line.strip() for line in lines)\n",
        "\n",
        "# Define the pattern\n",
        "p = \"GCTGATCGATCGTACG\"\n",
        "\n",
        "# Find the best match and calculate its edit distance\n",
        "best_match = min([edit_distance(p, t[i:i+len(p)]) for i in range(len(t) - len(p) + 1)])\n",
        "print(\"Edit distance of the best match:\", best_match)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc8RGuY0apKH",
        "outputId": "751ca23d-885c-4cfb-b72b-5f6ee6f6a3e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edit distance of the best match: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the edit distance of the best match between pattern\n",
        "GATTTACCAGATTGAG\n",
        "GATTTACCAGATTGAG and the excerpt of human chromosome 1?  (Don't consider reverse complements.)"
      ],
      "metadata": {
        "id": "DQ6okyLabxXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_distance(str1, str2):\n",
        "    m, n = len(str1), len(str2)\n",
        "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if str1[i - 1] == str2[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "            else:\n",
        "                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n",
        "\n",
        "    return dp[m][n]\n",
        "\n",
        "# Load the excerpt of human chromosome 1\n",
        "with open(\"chr1.GRCh38.excerpt.fasta\") as f:\n",
        "    lines = f.readlines()[1:]\n",
        "    t = ''.join(line.strip() for line in lines)\n",
        "\n",
        "# Define the pattern\n",
        "p = \"GATTTACCAGATTGAG\"\n",
        "\n",
        "# Find the best match and calculate its edit distance\n",
        "best_match = min([edit_distance(p, t[i:i+len(p)]) for i in range(len(t) - len(p) + 1)])\n",
        "print(\"Edit distance of the best match:\", best_match)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4aMU8CBbgS9",
        "outputId": "f4ecb1a0-4177-422b-81fd-8d1065af989b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edit distance of the best match: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def overlap(a, b, min_length=3):\n",
        "    \"\"\" Return length of longest suffix of 'a' matching\n",
        "        a prefix of 'b' that is at least 'min_length'\n",
        "        characters long.  If no such overlap exists,\n",
        "        return 0. \"\"\"\n",
        "    start = 0  # start all the way at the left\n",
        "    while True:\n",
        "        start = a.find(b[:min_length], start)  # look for b's prefix in a\n",
        "        if start == -1:  # no more occurrences to right\n",
        "            return 0\n",
        "        # found occurrence; check for full suffix/prefix match\n",
        "        if b.startswith(a[start:]):\n",
        "            return len(a)-start\n",
        "        start += 1  # move just past previous match\n",
        "\n",
        "def find_suffix_prefix_matches(reads, min_length=30):\n",
        "    suffixes = {}\n",
        "    overlaps = set()\n",
        "\n",
        "    # Step 1: Create a dictionary where each key is a length-30 suffix of a read\n",
        "    for read in reads:\n",
        "        suffix = read[-min_length:]\n",
        "        if suffix not in suffixes:\n",
        "            suffixes[suffix] = set()\n",
        "        suffixes[suffix].add(read)\n",
        "\n",
        "    # Step 2: Find overlaps involving each read's suffix\n",
        "    for read in reads:\n",
        "        suffix = read[-min_length:]\n",
        "        if suffix in suffixes:\n",
        "            for other_read in suffixes[suffix]:\n",
        "                if other_read != read:\n",
        "                    olen = overlap(read, other_read, min_length)\n",
        "                    if olen >= min_length:\n",
        "                        overlaps.add((read, other_read))\n",
        "\n",
        "    return overlaps\n",
        "\n",
        "# Step 1: Download and parse the reads from the provided FASTQ file\n",
        "reads = []\n",
        "with open(\"ERR266411_1.for_asm.fastq\") as f:\n",
        "    for line in f:\n",
        "        if not line.startswith(\"@\"):  # Ignore read names\n",
        "            reads.append(line.strip())\n",
        "\n",
        "# Step 2: Find all pairs of reads with an exact suffix/prefix match of length at least 30\n",
        "matches = find_suffix_prefix_matches(reads)\n",
        "\n",
        "# Step 3: Count the number of distinct pairs of reads that overlap\n",
        "num_edges = len(matches)\n",
        "print(\"Number of edges in the overlap graph:\", num_edges)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWyNVrRnboir",
        "outputId": "3ab66618-ddb1-459f-db6f-7886c1640046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of edges in the overlap graph: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Download and parse the reads from the provided FASTQ file\n",
        "reads = []\n",
        "with open(\"ERR266411_1.for_asm.fastq\") as f:\n",
        "    for line in f:\n",
        "        if not line.startswith(\"@\"):  # Ignore read names\n",
        "            reads.append(line.strip())\n",
        "\n",
        "# Step 2: Find all pairs of reads with an exact suffix/prefix match of length at least 30\n",
        "matches = find_suffix_prefix_matches(reads)\n",
        "\n",
        "# Step 3: Extract all unique reads involved in overlaps\n",
        "nodes_with_edges = set()\n",
        "for read_pair in matches:\n",
        "    nodes_with_edges.add(read_pair[0])\n",
        "    nodes_with_edges.add(read_pair[1])\n",
        "\n",
        "# Step 4: Count the number of nodes with at least one outgoing edge\n",
        "num_nodes_with_edges = len(nodes_with_edges)\n",
        "print(\"Number of nodes with at least one outgoing edge:\", num_nodes_with_edges)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXr4yI6Vcxdn",
        "outputId": "8382c961-b5b3-48e1-bee2-8fe1dc1dd732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes with at least one outgoing edge: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Download and parse the reads from the provided FASTQ file\n",
        "reads = []\n",
        "with open(\"ERR266411_1.for_asm.fastq\") as f:\n",
        "    for line in f:\n",
        "        if not line.startswith(\"@\"):  # Ignore read names\n",
        "            reads.append(line.strip())\n",
        "\n",
        "# Step 2: Find all pairs of reads with an exact suffix/prefix match of length at least 30\n",
        "matches = find_suffix_prefix_matches(reads)\n",
        "\n",
        "# Step 3: Extract all unique reads involved in overlaps\n",
        "nodes_with_edges = set()\n",
        "for read_pair in matches:\n",
        "    nodes_with_edges.add(read_pair[0])\n",
        "    nodes_with_edges.add(read_pair[1])\n",
        "\n",
        "# Step 4: Count the number of nodes with at least one outgoing edge\n",
        "num_nodes_with_edges = len(nodes_with_edges)\n",
        "print(\"Number of nodes with at least one outgoing edge:\", num_nodes_with_edges)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E5v8Jl2dDaB",
        "outputId": "e6fe9962-4540-468d-d68a-3f17fea4f03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes with at least one outgoing edge: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if reads are correctly parsed\n",
        "print(\"Number of reads:\", len(reads))\n",
        "print(\"Example reads:\")\n",
        "for read in reads[:5]:\n",
        "    print(read)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uZbGzbEdQiF",
        "outputId": "238624a5-1172-462d-a1be-daf96b6f3aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reads: 28865\n",
            "Example reads:\n",
            "TAAACAAGCAGTAGTAATTCCTGCTTTATCAAGATAATTTTTCGACTCATCAGAAATATCCGAAAGTGTTAACTTCTGCGTCATGGAAGCGATAAAACTC\n",
            "+\n",
            "B@DFEFFFGEGGGHEHGHGHGGGGHIFGFIFHICFGHGHGJGHFGHGIHEHGGHJGFEFHGHEGGHHGHIFGFGDIFGGFGGGFHGGGHGGGAGIFGGCG\n",
            "AACAAGCAGTAGTAATTCCTGCTTTATCAAGATAATTTTTCGACTCATCAGAAATATACGAAAGTGTTAACTTCTGCGTCATGGACACGAAAAAACTCCC\n",
            "+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the overlap function\n",
        "overlap_length1 = overlap(\"TAAACAAGCAGTAGTAATTCCTGCTTTATCAAGATAATTTTTCGACTCATCAGAAATATCCGAAAGTGTTAACTTCTGCGTCATGGAAGCGATAAAACTC\", \"AACAAGCAGTAGTAATTCCTGCTTTATCAAGATAATTTTTCGACTCATCAGAAATATACGAAAGTGTTAACTTCTGCGTCATGGACACGAAAAAACTCCC\")\n",
        "print(\"Overlap length:\", overlap_length1)\n",
        "\n",
        "overlap_length2 = overlap(\"TAAACAAGCAGTAGTAATTCCTGCTTTATCAAGATAATTTTTCGACTCATCAGAAATATCCGAAAGTGTTAACTTCTGCGTCATGGAAGCGATAAAACTC\", \"CGATAAAACTCTCAAGTTGCTTTTCTTCAGCTTGGCGGAGAAGTCAAGTAACTTGGCCGGGGTCGTTTGCTGGCACATACCCATGCAAGCGTGAAACTT\")\n",
        "print(\"Overlap length:\", overlap_length2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR8TDYhYdiJZ",
        "outputId": "84cf0d7a-2a48-4b12-8f88-5b1715e1bee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overlap length: 0\n",
            "Overlap length: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def parse_fastq(filename):\n",
        "    \"\"\"Parse a FASTQ file and return a list of reads.\"\"\"\n",
        "    reads = []\n",
        "    with open(filename, 'r') as file:\n",
        "        for line in file:\n",
        "            # Skip description lines\n",
        "            if line[0] == '@':\n",
        "                next(file)\n",
        "                reads.append(next(file).strip())\n",
        "    return reads\n",
        "\n",
        "def get_kmers(read, k):\n",
        "    \"\"\"Generate all k-mers of length k from a read.\"\"\"\n",
        "    return [read[i:i+k] for i in range(len(read) - k + 1)]\n",
        "\n",
        "def build_kmer_index(reads, k):\n",
        "    \"\"\"Build a dictionary where each k-mer is associated with a set of reads containing that k-mer.\"\"\"\n",
        "    kmer_index = defaultdict(set)\n",
        "    for read_id, read in enumerate(reads):\n",
        "        for kmer in get_kmers(read, k):\n",
        "            kmer_index[kmer].add(read_id)\n",
        "    return kmer_index\n",
        "\n",
        "def find_overlaps(reads, k, min_length):\n",
        "    \"\"\"Find all pairs of reads with an exact suffix/prefix match of length at least min_length.\"\"\"\n",
        "    kmer_index = build_kmer_index(reads, k)\n",
        "    overlap_pairs = set()\n",
        "    for read_id, read in enumerate(reads):\n",
        "        suffix = read[-k:]\n",
        "        for other_read_id in kmer_index[suffix]:\n",
        "            if read_id != other_read_id:\n",
        "                other_read = reads[other_read_id]\n",
        "                overlap_length = overlap(read, other_read, min_length)\n",
        "                if overlap_length >= min_length:\n",
        "                    overlap_pairs.add((read_id, other_read_id))\n",
        "    return overlap_pairs\n",
        "\n",
        "# Parse the FASTQ file\n",
        "filename = \"ERR266411_1.for_asm.fastq\"\n",
        "reads = parse_fastq(filename)\n",
        "\n",
        "# Find overlaps\n",
        "k = 6\n",
        "min_length = 30\n",
        "overlap_pairs = find_overlaps(reads, k, min_length)\n",
        "\n",
        "# Count the number of distinct pairs of reads that overlap\n",
        "num_edges = len(overlap_pairs)\n",
        "print(\"Number of edges in the overlap graph:\", num_edges)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB70n8DbfQ6J",
        "outputId": "c613923d-09dc-40bd-98ac-a4fe8fc2867d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of edges in the overlap graph: 12114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def parse_fastq(filename):\n",
        "    \"\"\"Parse a FASTQ file and return a list of reads.\"\"\"\n",
        "    reads = []\n",
        "    with open(filename, 'r') as file:\n",
        "        for line in file:\n",
        "            # Skip description lines\n",
        "            if line[0] == '@':\n",
        "                next(file)\n",
        "                reads.append(next(file).strip())\n",
        "    return reads\n",
        "\n",
        "def overlap(a, b, min_length=3):\n",
        "    \"\"\"Return length of longest suffix of 'a' matching a prefix of 'b' that is at least 'min_length' characters long.\"\"\"\n",
        "    start = 0  # start all the way at the left\n",
        "    while True:\n",
        "        start = a.find(b[:min_length], start)  # look for b's prefix in a\n",
        "        if start == -1:  # no more occurrences to right\n",
        "            return 0\n",
        "        # found occurrence; check for full suffix/prefix match\n",
        "        if b.startswith(a[start:]):\n",
        "            return len(a)-start\n",
        "        start += 1  # move just past previous match\n",
        "\n",
        "def get_kmers(read, k):\n",
        "    \"\"\"Generate all k-mers of length k from a read.\"\"\"\n",
        "    return [read[i:i+k] for i in range(len(read) - k + 1)]\n",
        "\n",
        "def build_kmer_index(reads, k):\n",
        "    \"\"\"Build a dictionary where each k-mer is associated with a set of reads containing that k-mer.\"\"\"\n",
        "    kmer_index = defaultdict(set)\n",
        "    for read_id, read in enumerate(reads):\n",
        "        for kmer in get_kmers(read, k):\n",
        "            kmer_index[kmer].add(read_id)\n",
        "    return kmer_index\n",
        "\n",
        "def find_overlaps(reads, k, min_length):\n",
        "    \"\"\"Find all pairs of reads with an exact suffix/prefix match of length at least min_length.\"\"\"\n",
        "    kmer_index = build_kmer_index(reads, k)\n",
        "    overlap_pairs = set()\n",
        "    for read_id, read in enumerate(reads):\n",
        "        suffix = read[-k:]\n",
        "        for other_read_id in kmer_index[suffix]:\n",
        "            if read_id != other_read_id:\n",
        "                other_read = reads[other_read_id]\n",
        "                overlap_length = overlap(read, other_read, min_length)\n",
        "                if overlap_length >= min_length:\n",
        "                    overlap_pairs.add((read_id, other_read_id))\n",
        "    return overlap_pairs\n",
        "\n",
        "def build_overlap_graph(reads, k, min_length):\n",
        "    \"\"\"Build an overlap graph where each read is a node and edges represent overlaps.\"\"\"\n",
        "    overlap_graph = defaultdict(set)\n",
        "    kmer_index = build_kmer_index(reads, k)\n",
        "    for read_id, read in enumerate(reads):\n",
        "        suffix = read[-k:]\n",
        "        for other_read_id in kmer_index[suffix]:\n",
        "            if read_id != other_read_id:\n",
        "                other_read = reads[other_read_id]\n",
        "                overlap_length = overlap(read, other_read, min_length)\n",
        "                if overlap_length >= min_length:\n",
        "                    overlap_graph[read_id].add(other_read_id)\n",
        "    return overlap_graph\n",
        "\n",
        "# Parse the FASTQ file\n",
        "filename = \"ERR266411_1.for_asm.fastq\"\n",
        "reads = parse_fastq(filename)\n",
        "\n",
        "# Build the overlap graph\n",
        "k = 6\n",
        "min_length = 30\n",
        "overlap_graph = build_overlap_graph(reads, k, min_length)\n",
        "\n",
        "# Count the number of nodes with at least one outgoing edge\n",
        "num_nodes_with_outgoing_edge = sum(1 for node_edges in overlap_graph.values() if len(node_edges) > 0)\n",
        "print(\"Number of nodes with at least one outgoing edge:\", num_nodes_with_outgoing_edge)\n"
      ],
      "metadata": {
        "id": "Sk5xte2ofhki",
        "outputId": "16587d6f-78f3-4fee-a0c4-88a3ee714117",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes with at least one outgoing edge: 623\n"
          ]
        }
      ]
    }
  ]
}